# image-caption-app

A small but practical Python script that combines computer vision with natural language generation â€” using a single Flask API and a Hugging Face model.
The idea was simple:
 Take an uploaded image â†’ run it through a vision-language transformer model â†’ return a caption.
âš™ï¸ What I used: â€¢ Python + Flask for the API
 â€¢ Hugging Face ViT-GPT2 model for image captioning
 â€¢ PyTorch for model inference
 â€¢ Pillow (PIL) for image handling
ğŸ” What I explored: â€¢ How pretrained vision-language models work in practice
 â€¢ Running inference locally in a minimal Flask app
 â€¢ Handling file uploads and integrating model logic into a simple backend
 â€¢ Debugging common API issues (KeyErrors, method routing, etc.)
Projects like this make it easier to understand what it actually takes to deploy AI â€” not just train models. From image upload to output caption, everything is handled in a streamlined local environment.
Always learning, always building and always open to conversations with folks working on similar things ğŸ‘©ğŸ»â€ğŸ’»
